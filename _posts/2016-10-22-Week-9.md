---
layout: post
title: Week 9 (10/15 - 10/22)
---

**This past week** saw the conclusion of the Allocator assignment and a focus on using STL's vector class to understand more C++ concepts.

**There isn't too much in my way.** With the assignment out of the way, I just had classes left.

**Next week**, we'll most likely continue to learn concepts and be given Project #4.

Class
-----
We've been slowly working through building an STL-like vector implementation.

Downing gave a particularly memorable analogy to explain the [copy-and-swap](https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms/Copy-and-swap) idiom. If your best friend just died and was about to be buried with his stuff in ancient Egypt, this would be a prime opportunity to swap your trash with his nice stuff. 

He's also been having fun trying to catch people by asking what a constructor should return. The quiz question over copy-and-swap caught everyone who (by now reflexively) answer "const reference" for parameter type. I thought our discussion of using allocators rather than new/delete made a lot of sense, since Downing emphasized time complexity as the motivation. 

Allocators
--------------------
As a post-mortem, I'm describing Project #3 as the nicest thing Downing has done for us. I'm expecting the next two assignments to be significantly more challenging, but it was good to have a breather without the GitHub Classroom/Boost Serialization/what's happening of the last assignment.

It's a nice exercise to implement an allocator, because it teaches you how to do pointer math correctly and what's happening underneath the hood (well, a highly simplified version) of actual memory management in an operating system. Understanding first-fit vs. best-fit and worst-fit is an interesting exercise when considering the trade-offs (really, they're all about the same).

Linux internally uses a slab allocator and a buddy system in some parts, caching common kernel data structure-sized chunks of memory and using tiers of those sizes to more efficiently perform its own tasks. A buddy system trivializes splitting and coalescing but leads to significant internal fragmentation; thus it's usually used to manage the smaller chunks taking off a slab.

Tip of the Week
---------------
[Type inference](https://en.wikipedia.org/wiki/Type_inference) is really cool. You save the programmer from having to explicitly annotate types on everything they type, but you still have a static type system.

If you've ever wondered how Java generics and the C++11 auto keyword work, you have two options.

1. Take a programming languages course. Professor Tom Dillig's honors PL, offered in the fall (right now), is a really great course.
2. Read the following material:
	- [cppreference](http://en.cppreference.com/w/cpp/language/auto) 
	- [Java Generics](http://docs.oracle.com/javase/tutorial/java/generics/genTypeInference.html)
	- [Hindley-Milner type system](https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system), the "most important programming languages discovery of the 1980s"

Languages like OCaml, Haskell, and F# support full type inference. Of course, the issue with full type inference is that functions no longer have type annotations on their return types and method signature. This is why C++11's auto strikes a really nice balance, where type annotations are required by default, and the compiler notifies you when it can't deduce a type.
